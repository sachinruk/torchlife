---

title: Survival Analysis Theory

keywords: fastai
sidebar: home_sidebar

summary: "The maths behind survival analysis."
description: "The maths behind survival analysis."
---
<!--

#################################################
### THIS FILE WAS AUTOGENERATED! DO NOT EDIT! ###
#################################################
# file to edit: SAT.ipynb
# command to build the docs after a change: nbdev_build_docs

-->

<div class="container" id="notebook-container">
        
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Much of the work here is summarised from the notes in <a href="https://data.princeton.edu/wws509/notes/c7s1">Generalised Linear Models by Germán Rodríguez</a>, Chapter 7.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="The-Survival-Function">The Survival Function<a class="anchor-link" href="#The-Survival-Function"> </a></h2><p>Let us define $S(t)$ to be the probability that an object will survive beyond time $t$. If $f(t)$ is the <strong>instantaneous</strong> probability that a death would be observed at time $t$, the survival function is defined as:
$$
S(t) = P(T &gt; t) = 1 - \int_{-\infty}^t f(x) dx
$$</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="The-Hazard-Function">The Hazard Function<a class="anchor-link" href="#The-Hazard-Function"> </a></h2><p>Another important concept is the hazard function, $\lambda(t)$, which is the <strong>instantaneous rate</strong> of occurence, given that the object has survived until time $t$.
$$
\lambda(t) = \lim\limits_{dt\to0} \frac{P(t&lt;T&lt;t+dt | T &gt; t)}{dt}\\
$$</p>
<p>The above can be simplified down by using Bayes Rule, and the definition of $S(t)$ above:
$$
\begin{aligned}
\lambda(t) =&amp; \lim\limits_{dt\to0} \frac{P(t&lt;T&lt;t+dt, T &gt; t)}{P(T &gt; t)\quad dt}\\
=&amp; \lim\limits_{dt\to0} \frac{P(t&lt;T&lt;t+dt)}{dt} \frac{1}{S(t)}\\
=&amp; \frac{f(t)}{S(t)}
\end{aligned}
$$</p>
<p>Since $S'(t) = -f(t)$ from the first equation, we can also state:
$$
\lambda(t) = - \frac{d}{dt}\log S(t)
$$</p>
<p>Therefore, the survival function will can be stated as:
$$
S(t) = \exp\left(-\int_{-\infty}^t \lambda(x) dx\right)
$$
and this will come in handy when we are coding up the survival function.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Likelihood-Function">Likelihood Function<a class="anchor-link" href="#Likelihood-Function"> </a></h2><p>In any probabilistic framework we wish to maxmise the likelihood of observed data given the probability functions. However, unlike classification/ regression situations we need to modify the likelihood $f(t)$. Let us define the case where death, $d_i$ hasn't been observed as censored observations. In those case we know that death will occur at a point $T &gt; t$. Therefore the likelihood $L$ can be defined as:
$$
L_i = \begin{cases}
f(t_i) = S(t_i)\lambda(t_i) &amp;\text{ when }d_i = 1 \\
\int^{\infty}_t f(x) dx = S(t_i) &amp;\text{ when }d_i = 0
\end{cases}
$$</p>
<p>The above can be simplified as:
$$
\begin{aligned}
L =&amp; \prod_{i=1}^N L_i = \prod_{i=1}^N \lambda(t_i)^{d_i} S(t_i) \\
\log L =&amp; \sum_{i=1}^N d_i \log \lambda(t_i) - \Lambda(t_i) \\
-\log L =&amp; \sum_{i=1}^N \Lambda(t_i) - d_i \log \lambda(t_i)
\end{aligned}
$$
where $\Lambda(t)\equiv -\log S(t)$ is cumulative hazard function.</p>
<p>Similarly if we wish to avoid taking into account the hazard function, we can define the likelihood function to be:
$$
\begin{aligned}
L =&amp; \prod_{i=1}^N L_i = \prod_{i=1}^N f(t_i)^{d_i} S(t_i)^{1-d_i} \\
-log L =&amp; -\sum_{i=1}^N d_i \log f(t_i) + (1 - d_i) \log S(t_i)
\end{aligned}
$$</p>
<p>These two formats of the likelihood will be used when modelling the behaviours of censored data (in different modelling settings). We use the negative log likelihood as this is more accommodating for modern deep learning libraries that do gradient descent.</p>

</div>
</div>
</div>
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span> 
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

</div>
 

