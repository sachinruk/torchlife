{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data\n",
    "> Functions used to create pytorch `DataSet`s and `DataLoader`s."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from fastai.data_block import DataBunch, DatasetType\n",
    "\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hide\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "class Data(Dataset):\n",
    "    \"\"\"\n",
    "    Create pyTorch Dataset\n",
    "    parameters:\n",
    "    - x: features\n",
    "    - t: time elapsed\n",
    "    - e: (death) event observed. 1 if observed, 0 otherwise.\n",
    "    - b: breakpoints where the hazard is different to previous segment of time.\n",
    "    \"\"\"\n",
    "    def __init__(self, t, e, b=None, x=None):\n",
    "        super().__init__()\n",
    "        assert isinstance(b, np.ndarray) or isinstance(b, list) or b is None\\\n",
    "                , \"Breakpoints need to be a list\"\n",
    "        self.x, self.t, self.e, self.b = x, t, e, b\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.t)\n",
    "    \n",
    "    def __getitem__(self, i):\n",
    "        time = torch.Tensor([self.t[i]])\n",
    "        e = torch.Tensor([self.e[i]])\n",
    "        \n",
    "        if self.b is None:\n",
    "            x_ = (time,)\n",
    "        else:\n",
    "            t_section = torch.LongTensor([np.searchsorted(self.b, self.t[i])])\n",
    "            x_ = (time, t_section.squeeze())\n",
    "        \n",
    "        if self.x is not None:\n",
    "            x = torch.Tensor(self.x[i])\n",
    "            x_ = x_ + (x,)\n",
    "            \n",
    "        return x_, e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([torch.Size([64, 1]), torch.Size([64, 3])], torch.Size([64, 1]))"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# hide\n",
    "np.random.seed(42)\n",
    "N = 100\n",
    "D = 3\n",
    "p = 0.1\n",
    "bs = 64\n",
    "\n",
    "x = np.random.randn(N, D)\n",
    "t = np.arange(N)\n",
    "e = np.random.binomial(1, p, N)\n",
    "\n",
    "data = Data(t, e, x=x)\n",
    "batch = next(iter(DataLoader(data, bs)))\n",
    "assert len(batch[-1]) == bs, (f\"length of batch {len(batch)} is different\" \n",
    "                          f\"to intended batch size {bs}\")\n",
    "[b.shape for b in batch[0]], batch[1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[torch.Size([64, 1]), torch.Size([64]), torch.Size([64, 3])] torch.Size([64, 1])\n"
     ]
    }
   ],
   "source": [
    "# hide\n",
    "N = 100\n",
    "D = 3\n",
    "p = 0.1\n",
    "bs = 64\n",
    "breakpoints = [10, 50]\n",
    "\n",
    "data = Data(t, e, breakpoints, x)\n",
    "batch2 = next(iter(DataLoader(data, bs)))\n",
    "assert len(batch2[-1]) == bs, (f\"length of batch {len(batch2)} is different\" \n",
    "                          f\"to intended batch size {bs}\")\n",
    "print([b.shape for b in batch2[0]], batch2[1].shape)\n",
    "\n",
    "assert torch.all(batch[0][0] == batch2[0][0]), (\"Discrepancy between batch \"\n",
    "                                                \"with breakpoints and without\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "class DataFrame(Data):\n",
    "    \"\"\"\n",
    "    Wrapper around Data Class that takes in a dataframe instead\n",
    "    parameters:\n",
    "    - df: dataframe. **Must have t (time) and e (event) columns, other cols optional.\n",
    "    - b: breakpoints of time (optional)\n",
    "    \"\"\"\n",
    "    def __init__(self, df, b=None):\n",
    "        t = df['t'].values\n",
    "        e = df['e'].values\n",
    "        x = df.drop(['t', 'e'], axis=1).values\n",
    "        if x.shape[1] == 0:\n",
    "            x = None\n",
    "        super().__init__(t, e, b, x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((tensor([1.]),), tensor([0.]))"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# hide\n",
    "# testing with pandas dataframe\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame({'t': t, 'e': e})\n",
    "df2 = DataFrame(df)\n",
    "df2[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((tensor([1.]), tensor([ 1.5230, -0.2342, -0.2341])), tensor([0.]))"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# hide\n",
    "# testing with x\n",
    "new_df = pd.concat([df, pd.DataFrame(x)], axis=1)\n",
    "df3 = DataFrame(new_df)\n",
    "df3[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((tensor([1.]), tensor(0), tensor([ 1.5230, -0.2342, -0.2341])), tensor([0.]))"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# hide\n",
    "# testing with breakpoints\n",
    "new_df = pd.concat([df, pd.DataFrame(x)], axis=1)\n",
    "df3 = DataFrame(new_df, breakpoints)\n",
    "df3[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "def create_db(df, b=None, train_p=0.8, bs=128, test_ds=False, test_p=0.2):\n",
    "    \"\"\"\n",
    "    Take dataframe and split into train, test, val (optional)\n",
    "    and convert to Fastai databunch\n",
    "\n",
    "    parameters:\n",
    "    - df: pandas dataframe\n",
    "    - b: breakpoints of time (optional)\n",
    "    - train_p: training percentage\n",
    "    - bs: batch size\n",
    "    - test_ds: whether to split into test set\n",
    "    - test_p: proportion of whats left over after taking out train set\n",
    "    \"\"\"\n",
    "    df.reset_index(drop=True, inplace=True)\n",
    "    if test_ds:\n",
    "        train_len = int((1-test_p)*len(df))\n",
    "        test_ds = DataFrame(df.iloc[train_len:], b)\n",
    "        df = df.iloc[:train_len]\n",
    "        test_dl = DataLoader(test_ds, bs=bs)\n",
    "\n",
    "    train_len = int(train_p*len(df))\n",
    "    train_ds = DataFrame(df.iloc[:train_len], b)\n",
    "    val_ds = DataFrame(df.iloc[train_len:], b)\n",
    "    \n",
    "    bs = min(bs, len(train_ds))\n",
    "    val_bs = min(bs, len(val_ds))\n",
    "    train_db = DataBunch.create(train_ds, val_ds, bs=bs, val_bs=val_bs)\n",
    "\n",
    "    if test_ds is not False:\n",
    "        return train_db, test_dl\n",
    "    else:\n",
    "        return train_db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted Cox_Proportional_Hazard.ipynb.\n",
      "Converted KaplanMeier.ipynb.\n",
      "Converted Survival Analysis Theory.ipynb.\n",
      "Converted data.ipynb.\n",
      "Converted index.ipynb.\n",
      "Converted utils.ipynb.\n"
     ]
    }
   ],
   "source": [
    "# hide\n",
    "from nbdev.export import *\n",
    "notebook2script()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
